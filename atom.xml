<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Max&#39;s Blog</title>
  <icon>https://www.gravatar.com/avatar/d02dec40f94389c9e1ed922fa6ad3ed2</icon>
  <subtitle>keep hungry, then you&#39;ll be really hungry</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-08-10T16:43:12.463Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Max Qi</name>
    <email>490949611@qq.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>20180811日记</title>
    <link href="http://yoursite.com/2018/08/11/title%2020180811%E6%97%A5%E8%AE%B0/"/>
    <id>http://yoursite.com/2018/08/11/title 20180811日记/</id>
    <published>2018-08-10T16:43:11.578Z</published>
    <updated>2018-08-10T16:43:12.463Z</updated>
    
    <content type="html"><![CDATA[<p>估计要暂别电脑一段时间，转型去线下学数学了～刚买了统计学习方法，之前数学底子太差了，要看点基础的东西，感触什么的就写在纸质笔记本里了，等看差不多了就来这篇日记打卡，把下面的flag挨个拔掉！</p><p>Flag～</p><p>Flag~</p><p>Flag~</p><p>Flag~</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;估计要暂别电脑一段时间，转型去线下学数学了～刚买了统计学习方法，之前数学底子太差了，要看点基础的东西，感触什么的就写在纸质笔记本里了，等看差不多了就来这篇日记打卡，把下面的flag挨个拔掉！&lt;/p&gt;
&lt;p&gt;Flag～&lt;/p&gt;
&lt;p&gt;Flag~&lt;/p&gt;
&lt;p&gt;Flag~&lt;/p
      
    
    </summary>
    
    
      <category term="life" scheme="http://yoursite.com/tags/life/"/>
    
  </entry>
  
  <entry>
    <title>mac在nginx下部署php遇到的坑</title>
    <link href="http://yoursite.com/2018/08/09/mac%E5%9C%A8nginx%E4%B8%8B%E9%83%A8%E7%BD%B2php%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91/"/>
    <id>http://yoursite.com/2018/08/09/mac在nginx下部署php遇到的坑/</id>
    <published>2018-08-08T16:43:26.827Z</published>
    <updated>2018-08-10T16:40:03.685Z</updated>
    
    <content type="html"><![CDATA[<p>受人之托，帮人部署一个网站，然后我想在本地的nginx里先调试一下。一开始，打开页面显示403，这个之前见过，nginx的权限问题，改了这个权限之后，发现访问php页面都是直接下载而没有解析，我想起来电脑可能没有php环境，就下了php，然后还是同样的问题。总之因为对php不太熟悉（之前都用xampp这类软件），所以花了一点时间才搞定。</p><p>首先要明白的是，nginx本身不能处理php，它只是一个web服务器，当前端请求php时，nginx需要把界面发给php解释器处理，然后把结果返回给前端。一般地，nginx是把请求发给fastcgi管理进程处理。如nginx中配置：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">location ~ \.php$ &#123;</span><br><span class="line">    root           html;</span><br><span class="line">    fastcgi_pass   127.0.0.1:9000;</span><br><span class="line">    fastcgi_index  index.php;</span><br><span class="line">    fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;#这里原来不是$document_root，搞得我很蒙，还好网上查到改好了，不然会报file not found</span><br><span class="line">    include        fastcgi_params;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>所以要启动一个fastcgi，这里就用到了php-fpm，它是一个php fastcgi管理器，只用于php语言（旧版php的要单独下php-fpm，我用的php-fpm已经集成了这个）。</p><p>这里有很多奇怪的问题。</p><p><strong>第一次运行php-fpm</strong></p><p>failed: 找不到/private/etc/php-fpm.conf文件，</p><p>Solution:但这个目录下有个php-fpm.conf.default的文件，所以cp了正确名字的新文件</p><p><strong>第二次远行php-fpm</strong></p><p>Failed: 找不到/usr/var/log/php-fpm.log </p><p>Solution：根本没有这个目录，到conf文件里改了但是没有效果，没办法我就通过下面的命令执行php-fpm(后面都用这个命令执行)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">php-fpm --fpm-config /private/etc/php-fpm.conf  --prefix /usr/local/var</span><br></pre></td></tr></table></figure><p><strong>第三次运行php-fpm</strong></p><p>Failed: No pool defined. at least one pool section must be specified in config file</p><p>Solution：到/etc/php-fpm.d/ 目录下有文件www.conf.default，cp一份名为<a href="http://www.conf的文件" target="_blank" rel="noopener">www.conf的文件</a></p><p><strong>第四次运行php-fpm</strong></p><p>Failed：端口被占用</p><p>Solution：杀掉这个进程</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo lsof -i tcp:9000#找到占用9000端口的进程号</span><br><span class="line">kill -9 port#杀！</span><br></pre></td></tr></table></figure><p><strong>第五次运行php-fpm</strong></p><p>成功！</p><p>##补充：</p><p>在nginx上配的时候又有所一点不同，在mac上php-fpm直接listen了9000端口，但在服务器上它listen了php7.0-fpm.sock但socket文件，这种方式可能快一点，所以要在nginx上php的配置那边将</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fastcgi_pass 127.0.0.1:9000;</span><br></pre></td></tr></table></figure><p>改成：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fastcgi_pass unix:/run/php/php7.0-fpm.sock;</span><br></pre></td></tr></table></figure><p>才能成功运行php</p><h3 id="继续补充"><a href="#继续补充" class="headerlink" title="继续补充"></a>继续补充</h3><p>很有意思的一个东西，要上传27m的一个视频，nginx直接报了413 Request Entity Too Large，是我没设置…</p><p>到nginx的配置（set-enabled/default）里面添加</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    ...</span><br><span class="line">    client_max_body_size 80m;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>重读配置、重启服务器</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nginx -s reload</span><br><span class="line">service nginx restart</span><br></pre></td></tr></table></figure><p>然后还要去修改php.ini，在其中修改两条配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">upload_max_filesize = 80M</span><br><span class="line">post_max_size = 80M</span><br></pre></td></tr></table></figure><p>然后关掉php-fpm的进程，再重启即可～</p><p>ps：贺老师真的完全不研究的…mp4传不上去只是在系统里没添加这种类型，这种事都要我自己去找…难受 :(</p><p><strong>note：</strong>在ubuntu下现在比较推荐用apt而不是apt-get…so，是时候改变了！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;受人之托，帮人部署一个网站，然后我想在本地的nginx里先调试一下。一开始，打开页面显示403，这个之前见过，nginx的权限问题，改了这个权限之后，发现访问php页面都是直接下载而没有解析，我想起来电脑可能没有php环境，就下了php，然后还是同样的问题。总之因为对php
      
    
    </summary>
    
    
      <category term="mac" scheme="http://yoursite.com/tags/mac/"/>
    
  </entry>
  
  <entry>
    <title>看Husky的一点整理</title>
    <link href="http://yoursite.com/2018/08/08/title%20%E7%9C%8BHusky%E7%9A%84%E4%B8%80%E7%82%B9%E6%95%B4%E7%90%86/"/>
    <id>http://yoursite.com/2018/08/08/title 看Husky的一点整理/</id>
    <published>2018-08-08T02:34:42.580Z</published>
    <updated>2018-08-10T10:36:33.002Z</updated>
    
    <content type="html"><![CDATA[<p>husky是一个通用的分布式的计算平台，就像mapreduce、spark这种，它是用c++写的（难受…）</p><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> Required</span><br><span class="line">master_host=master#master跑的地方</span><br><span class="line">master_port=10086#master绑定的端口</span><br><span class="line">comm_port=12306#worker绑定的端口</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> Worker information</span><br><span class="line">[worker]</span><br><span class="line">info=worker1:4#worker1有4个线程</span><br><span class="line">info=worker2:4#worker2有4个线程</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>如果用了hdfs，配置hdfs路径</span><br><span class="line">hdfs_namenode=master</span><br><span class="line">hdfs_namenode_port=9000</span><br></pre></td></tr></table></figure><p>运行的时候用</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./program --conf=/path/to/config.ini</span><br></pre></td></tr></table></figure><p>写入配置。</p><h2 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h2><h3 id="Object-List"><a href="#Object-List" class="headerlink" title="Object List"></a>Object List</h3><p>Object List（objList）是husky中最主要的对象，可以把任何对象都存在objlist中，两个objlist通过channel传递消息。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Obj</span> &#123;</span></span><br><span class="line">   <span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">using</span> KeyT = <span class="keyword">int</span>;</span><br><span class="line">    KeyT key;</span><br><span class="line">    <span class="function"><span class="keyword">const</span> KeyT&amp; <span class="title">id</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123; <span class="keyword">return</span> key; &#125;</span><br><span class="line">    Obj() = <span class="keyword">default</span>;</span><br><span class="line">    explicit Obj(const KeyT&amp; k) : key(k) &#123;&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>创建一个obj只要3步：</p><ol><li>定义一个key的类型（keyT），一般都用int</li><li>写一个id（）函数来返回该对象对应的key</li><li>需要一个默认构造函数，还需要一个能够接收key参数的构造函数</li></ol><p>接下来就可以创建、使用、删除Object List</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//创建名叫my_objlist的objlist</span></span><br><span class="line"><span class="keyword">auto</span>&amp; objlist = ObjListStore::create_objlist&lt;Obj&gt;(<span class="string">"my_objlist"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//将obj传入创建好的objlist中</span></span><br><span class="line"><span class="function">Obj <span class="title">obj</span><span class="params">(<span class="number">3</span>)</span></span>;</span><br><span class="line">objlist.add_object(obj);</span><br><span class="line"></span><br><span class="line"><span class="comment">//通过名字拿到对应的objlist，注意这里的auto关键字，自动判定类型，很舒服！</span></span><br><span class="line"><span class="keyword">auto</span>&amp; objlist2 = ObjListStore::get_objlist&lt;Obj&gt;(<span class="string">"my_objlist"</span>);  </span><br><span class="line"></span><br><span class="line"><span class="comment">//通过名字删除objlist</span></span><br><span class="line">ObjListStore::drop_objlist(<span class="string">"my_objlist"</span>);</span><br></pre></td></tr></table></figure><p>为了让添加在objlist中的obj被其他线程感知并利用，在多线程情况下需要将objlist全局化一下，husky已经封装好该方法</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">globalize(objlist);</span><br></pre></td></tr></table></figure><p>接下来就是<strong>最重要</strong>的一个函数list_execute（），它规定了list里的每个object需要做的事，这个函数是用户自己定义的。它有两个参数：</p><ul><li>第一个是要操作的objlist</li><li>第二个是这个objlist中每个obj要做的事，例如下面函数就是obj在log中打印id，包括之后用channel发送或接收消息也都是在这个函数里</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">list_execute(objlist, [](Obj&amp; obj) &#123;</span><br><span class="line">    base::log_msg(<span class="string">"My id is: "</span> + obj.id());</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h3 id="Channel"><a href="#Channel" class="headerlink" title="Channel"></a>Channel</h3><p>channel就是object和object互相通信的工具，他们的关系类似于城市和公路。husky中有四种channel：</p><ul><li>Push Channel：最常见的点对点通信</li><li>Push Combined Channel：在push channel基础上增加了合并发给同个obj的</li><li>Broadcast Channel：将一个key-value广播出去，任何地方都可以通过key拿到值</li><li>Migrate Channel：用来migrate对象，将一个对象发送到另一个线程上</li></ul><p>channel的创建、使用和drop（一定要主动销毁）</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// create PushChannel</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> MsgT, <span class="keyword">typename</span> DstObjT&gt; </span><br><span class="line"><span class="keyword">static</span> PushChannel&lt;MsgT, DstObjT&gt;&amp; </span><br><span class="line">create_push_channel(ChannelSource&amp; src_list,</span><br><span class="line">                    ObjList&lt;DstObjT&gt;&amp; dst_list,</span><br><span class="line">                    <span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span>&amp; name = <span class="string">""</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Get PushChannel through name</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> MsgT, <span class="keyword">typename</span> DstObjT&gt;</span><br><span class="line"><span class="keyword">static</span> PushChannel&lt;MsgT, DstObjT&gt;&amp; </span><br><span class="line">get_push_channel(<span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span>&amp; name = <span class="string">""</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Drop channel through name</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">drop_channel</span><span class="params">(<span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span>&amp; name)</span></span>;</span><br></pre></td></tr></table></figure><p>下面通过例子来说明：</p><p>首先，要想创建channel，就要确定发消息的源objlist和目的objlist，当然，参数里的目的objlist必须是全局化的</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//创建一个push_channel</span></span><br><span class="line"><span class="keyword">auto</span>&amp; ch = ChannelStore::create_push_channel&lt;<span class="keyword">int</span>&gt;(src_list, dst_list);</span><br></pre></td></tr></table></figure><p>一般来说，channel是放在list_execute（）函数里用的，要想清楚从哪个obj发，发什么，哪个obj接收（通过key来标注）</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//push channel</span></span><br><span class="line"><span class="comment">//发送端代码</span></span><br><span class="line">list_execute(src_list, [&amp;ch](Obj&amp; obj) &#123;</span><br><span class="line">    ch.push(msg, key);  <span class="comment">// send msg to key</span></span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">//接收端代码</span></span><br><span class="line">list_execute(dst_list, [&amp;ch](Obj&amp; obj) &#123;</span><br><span class="line">    <span class="keyword">auto</span>&amp; msgs = ch.get(obj); <span class="comment">// The msgs is of type std::vector&lt;MsgT&gt;, MsgT is int in this case</span></span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">//broadcast channel</span></span><br><span class="line"><span class="keyword">auto</span>&amp; ch4 = ChannelStore::create_broadcast_channel&lt;<span class="keyword">int</span>, <span class="built_in">std</span>::<span class="built_in">string</span>&gt;(src_list);</span><br><span class="line">list_execute(src_list, [&amp;ch4](Obj&amp; obj) &#123;</span><br><span class="line">    ch4.broadcast(key, value);  <span class="comment">// broadcast key, value pair</span></span><br><span class="line">&#125;);</span><br><span class="line">list_execute(src_list, [&amp;ch4](Obj&amp; obj) &#123;</span><br><span class="line">    <span class="keyword">auto</span> msg = ch4.get(key);   <span class="comment">// get the broadcasted value through key.</span></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>###Aggregator</p><p>用来执行一些聚合操作的类，可以用来做求前k大值，统计数量，计算机器学习梯度总数等。他的构造函数需要两个参数（或以上），一个是init值，另外是lambda函数</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Aggregator&lt;<span class="keyword">int</span>&gt; agg(<span class="number">0</span>, [](<span class="keyword">int</span>&amp; a, <span class="keyword">const</span> <span class="keyword">int</span>&amp; b)&#123; a += b; &#125;);</span><br></pre></td></tr></table></figure><p>这个lambda函数就是aggregate的规则。</p><p>在创建完agregator后，就要使用它了。可以用update函数或者update_any函数（比update可接受参数类型多）来进行aggregator，例如</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">agg.update(<span class="number">1</span>);<span class="comment">//aggregator值加1</span></span><br></pre></td></tr></table></figure><p>在聚合完之后，更新的值其实只在本地，为了让这个值在全局响应要用HuskyAggregatorFactory::sync()函数。另一种方式是通过HuskyAggregatorFactory::get_channel()来拿到通道，然后在list_execute中通过这个channel把消息传播出去，这种方法最后也会去调用sync()函数</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//两种方式</span></span><br><span class="line">AggregatorFactory::sync();</span><br><span class="line"></span><br><span class="line"><span class="comment">// or using aggregator channel</span></span><br><span class="line"><span class="keyword">auto</span>&amp; ac = AggregatorFactory::get_channel();</span><br><span class="line">list_execute(obj_list, &#123;&#125;, &#123;&amp;ac&#125;, [&amp;](OBJ&amp; obj) &#123; </span><br><span class="line">  ...  <span class="comment">// here we can give updates to some aggregators</span></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>当全局划这个聚合之后，就可以用get_value()函数得到值了</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> sum = agg.get_value()</span><br></pre></td></tr></table></figure><p>这个值是被全局共享的，所以对他的修改会影响其他executor，并可能有线程安全问题</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;husky是一个通用的分布式的计算平台，就像mapreduce、spark这种，它是用c++写的（难受…）&lt;/p&gt;
&lt;h2 id=&quot;配置&quot;&gt;&lt;a href=&quot;#配置&quot; class=&quot;headerlink&quot; title=&quot;配置&quot;&gt;&lt;/a&gt;配置&lt;/h2&gt;&lt;figure clas
      
    
    </summary>
    
    
      <category term="CUHK" scheme="http://yoursite.com/tags/CUHK/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop了解一下</title>
    <link href="http://yoursite.com/2018/08/05/hadoop%E4%BA%86%E8%A7%A3%E4%B8%80%E4%B8%8B/"/>
    <id>http://yoursite.com/2018/08/05/hadoop了解一下/</id>
    <published>2018-08-05T14:20:47.264Z</published>
    <updated>2018-08-10T10:37:01.798Z</updated>
    
    <content type="html"><![CDATA[<p>搞分布式数据分析系统，hadoop绝对是不可绕过的一关，所以简单玩了一下，以下是总结。</p><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>###Apache Hadoop与HDFS</p><p>Hadoop是一个大的生态系统，最主要是hdfs和一个基于mapreduce的分布式计算引擎。hdfs就是一个文件系统，在mapreduce的时候（包括用spark的时候）都需要对应文件在hdfs里。</p><p><strong>block块：</strong>HDFS在物理上是以block存储的，block大小可以通过配置参数（dfs.blocksize）来规定，默认128M，可以减少寻址开销。大文件会被切分成很多block来存，而小文件存储则不会占用整个块的空间。</p><p><strong>NameNode：</strong>是master。负责管理文件系统的namespace（可以理解是指向具体数据的文件名、路径名这种）和客户端对文件的访问。</p><p><strong>(非Yarn)JobTracker：</strong>在NameNode上，协调在集群运行的所有作业，分配要在tasktracker上运行的map和reduce任务。</p><p><strong>DataNode：</strong>是slave。datanode则负责数据的存储。</p><p><strong>(非Yarn)TaskTracker：</strong>在datanode上，运行分配的任务并定期向jobtracker报告进度。</p><p><strong>流式访问：</strong>指hdfs访问时像流水一样一点一点过。这样也决定了hdfs是一次写入、多次读取的特性，同时只能有一个wirhter。这样访问方式适合做数据分析，而不是网盘这种。</p><p><strong>rack-aware（机架感知）：</strong>这是hdfs的复制策略。hdfs为了数据可靠一般会将数据复制几份（默认三份）。同一个机架的机器传输速度快，不需要通过交换机。为了提高效率，一台机器的数据会把一个备份放在同一机架（相同rack id）的机器里，另一个备份放在其他机架的机器上。机架的错误率很小，所以不影响可靠性。</p><p><strong>hdfs的特点：</strong></p><ul><li>面对构成系统的组件数目很大，所以对硬件的快速检测错误并自动回复非常重要</li><li>hdfs需要流式访问他们的数据集</li><li>运行的数据集非常大，一个典型文件大小一般在几G到几T</li><li>文件访问模型是“一次写入、多次访问”</li><li>将计算移动到数据附近闭将数据移动到计算更好</li></ul><p>###Yarn：</p><p>yarn其实是解决了经典mapreduce中一些问题（例如：jobtracker太累导致的可扩展性问题）的新一代hadoop计算平台。</p><p><strong>ResourceManager：</strong>代替jobtracker，以后台进程的形式运行。追踪有哪些可用的活动节点和资源，指出哪些程序应该何时或者这些资源。</p><p><strong>ApplicationMaster：</strong>代替一个专用而短暂的JobTracker。用户提交一个应用程序时，会启动applicationmaster这个轻量级进程实例来协调程序内任务（监视进度、定时向resourcemanager发送心跳数据、负责容错等），计算数据需要的资源并向resourcemanager申请。它本身也是在一个container里运行的，且可能与它管理的任务运行在同一节点上。</p><p><strong>Container：</strong>是yarn中资源的抽象，封装了某个节点上一定量的资源（如cpu和内存等资源）。它的分配是由applicationmaster向resourcemanager申请的；而它的运行则是applicationmaster向资源所在的nodemanager发起的。</p><p><strong>NodeManager：</strong>代替tasktracker。拥有很多动态创建的资源Container。容器大小取决于它所包含资源量，而一个节点上的容器数量由配置参数和除用于后台进程和操作系统以外资源总量决定。</p><h2 id="基本架构"><a href="#基本架构" class="headerlink" title="基本架构"></a>基本架构</h2><p>Hdfs采用了master/slave架构。一个hdfs集群由一个namenode和一群datanodes组成。简单来说，就是hdfs通过namenode暴露出了文件系统命名空间的操作，包括打卡、关闭、重命名文件等等。在这个文件系统对一块数据的操作会映射到具体的datanodes上。</p><p>所以一般是一台机器上搭namenode，然后datanode在其他各个机器上。</p><p><img src="/Users/max/Documents/Blog/source/img/hdfsarchitecture.gif" alt="hdfsarchitecture"></p><p>##基本操作</p><p>###单节点测试</p><p>比较无聊，只是测一下能不能跑，不需要运行什么</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> cd Cellar/hadoop/3.1.0/libexec</span><br><span class="line"><span class="meta">$</span> mkdir input#不能是别的名字</span><br><span class="line"><span class="meta">$</span> cp etc/hadoop/*.xml input</span><br><span class="line"><span class="meta">$</span> hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.0.jar  grep input output 'dfs[a-z.]+'</span><br><span class="line"><span class="meta">$</span> cat output/*</span><br></pre></td></tr></table></figure><p>###伪分布式测试（pseudo-distributed）</p><ol><li><p>保证本机已经装好hadoop，java1.8（java9有些函数被废了会报错）</p></li><li><p>配置本机ssh，确保</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh localhost#mac默认不允许，需要手动去打开</span><br></pre></td></tr></table></figure><p>可以运行。注意：mac默认不允许任何机器远程登录，需要到  系统偏好设置 -&gt; 共享 去勾选远程登录。</p></li><li><p>配置HDFS，包括core-site.xml文件和hdfs-site.xml文件。前者配置用于存储HDFS的临时文件目录和hdsf访问端口，后者确定复制份数</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- core-site.xml --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop/libexec/tmp/hadoop- $&#123;user.name&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--如果无此目录则去mkdir一个--&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">description</span>&gt;</span>A base for other temporary directories.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.default.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- hdfs-site.xml --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>格式化HDFS</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure><p>成功的话在tmp目录下可以看到dfs文件</p></li><li><p>启动各个节点</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hdfs --daemon start NameNode#启动namenode</span><br><span class="line">hdfs --daemon start DataNode#启动datanode</span><br><span class="line">hdfs --daemon start SecondaryNameNode#它是namenode的快照，保证了namenode的更新</span><br><span class="line"><span class="meta">jps#</span>用来查看这些节点是否真的启动了</span><br></pre></td></tr></table></figure></li><li><p>在HDFS上创建文件夹及文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -mkdir /demo#在hdfs上创建demo文件夹</span><br><span class="line">hdfs dfs -ls /demo</span><br><span class="line">hdfs dfs -put test.input /demo#将本地的test.input文件发到hdfs上</span><br></pre></td></tr></table></figure></li><li><p>配置Yarn的mapred-site.xml和yarn-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- mapred-sited.xml --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.application.classpath<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">value</span>&gt;</span>share/hadoop/mapreduce/*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 如果不加这个property，在后面运行mapreduce任务时会报找不到包 --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- yarn-site.xml --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- Site specific YARN configuration properties --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>localhost<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>启动resourcemanager和nodemanager</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yarn --daemon start nodemanager</span><br><span class="line">yarn --daemon start resourcemanager</span><br></pre></td></tr></table></figure><p>yarn端口是8088，可以去localhost:8088看页面</p></li><li><p>运行mapreduce任务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn jar hadoop-mapreduce-examples-3.1.0.jar wordcount /demo/test.input /demo-output/</span><br></pre></td></tr></table></figure><p>可以到对应文件里查看运行结果</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;搞分布式数据分析系统，hadoop绝对是不可绕过的一关，所以简单玩了一下，以下是总结。&lt;/p&gt;
&lt;h2 id=&quot;基本概念&quot;&gt;&lt;a href=&quot;#基本概念&quot; class=&quot;headerlink&quot; title=&quot;基本概念&quot;&gt;&lt;/a&gt;基本概念&lt;/h2&gt;&lt;p&gt;###Apache H
      
    
    </summary>
    
    
      <category term="big data" scheme="http://yoursite.com/tags/big-data/"/>
    
  </entry>
  
  <entry>
    <title>Spark基础学习</title>
    <link href="http://yoursite.com/2018/08/05/spark%E4%BA%86%E8%A7%A3%E4%B8%80%E4%B8%8B/"/>
    <id>http://yoursite.com/2018/08/05/spark了解一下/</id>
    <published>2018-08-05T13:38:09.544Z</published>
    <updated>2018-08-10T10:36:37.615Z</updated>
    
    <content type="html"><![CDATA[<p>看了研究生的project，选择了分布式系统下的数据挖掘的项目，所以先来搞一点spark的的东西，免得什么都不会。。。</p><h3 id="RDD-resilient-distributed-dataset，弹性分布式数据集"><a href="#RDD-resilient-distributed-dataset，弹性分布式数据集" class="headerlink" title="RDD(resilient distributed dataset，弹性分布式数据集)"></a>RDD(resilient distributed dataset，弹性分布式数据集)</h3><p>spark RDD与hadoop的mapreduce要做的类似，都是实现对大数据的分布式处理。但spark RDD解决的痛点主要是</p><ul><li>迭代式的机器学习算法</li><li>交互式数据挖掘</li></ul><p>这两项在mapreduce下都难以完成，而RDD通过<strong>对分布式集群的内存资源进行抽象，允许程序高效复用已有的中间结果。</strong>解决了上述问题</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;看了研究生的project，选择了分布式系统下的数据挖掘的项目，所以先来搞一点spark的的东西，免得什么都不会。。。&lt;/p&gt;
&lt;h3 id=&quot;RDD-resilient-distributed-dataset，弹性分布式数据集&quot;&gt;&lt;a href=&quot;#RDD-resilie
      
    
    </summary>
    
    
      <category term="big data" scheme="http://yoursite.com/tags/big-data/"/>
    
  </entry>
  
  <entry>
    <title>一些使用homebrew的经验</title>
    <link href="http://yoursite.com/2018/08/02/%E4%B8%80%E4%BA%9B%E4%BD%BF%E7%94%A8homebrew%E7%9A%84%E7%BB%8F%E9%AA%8C/"/>
    <id>http://yoursite.com/2018/08/02/一些使用homebrew的经验/</id>
    <published>2018-08-02T04:05:26.949Z</published>
    <updated>2018-08-10T10:33:40.404Z</updated>
    
    <content type="html"><![CDATA[<p>现在新的mac基本都内置homebrew了吧，brew可以说是mac神器之一了。上手简单，但还是用法需要整理一下：</p><p>###brew常用命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">brew search 包名 #搜索包</span><br><span class="line">brew info 包名#包信息</span><br><span class="line">brew list #查看有哪些包</span><br><span class="line">brew install 包名#安装包</span><br><span class="line">brew uninstall 包名#删除包</span><br></pre></td></tr></table></figure><h3 id="brew管理服务"><a href="#brew管理服务" class="headerlink" title="brew管理服务"></a>brew管理服务</h3><p>brew还有个重要的任务就是管理服务，在我本机的：</p><ul><li>Kafka</li><li>mysql</li><li>nginx</li><li>Redis</li><li>zookeeper</li></ul><p>都是用了brew进行管理，管理他们用</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">brew services start 服务名#开启一个service</span><br><span class="line">brew services stop 服务名#关闭一个service</span><br></pre></td></tr></table></figure><p>每次开启一个服务，就会在～/Library/LaunchAgents里面增加一个plist文件，用来存储这个服务的一些版本信息，同时，本机所有其他服务可以通过</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">launchctl load *.plist #加载 </span><br><span class="line">launchctl unload *.plist #取消</span><br><span class="line">launchctl list#查看服务</span><br></pre></td></tr></table></figure><p>来完成</p><h3 id="brew其他命令"><a href="#brew其他命令" class="headerlink" title="brew其他命令"></a>brew其他命令</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew link 包名</span><br></pre></td></tr></table></figure><p>这里的link是指symbollink（有点类似于windows里的创建快捷方式）。以hadoop为例，在brew刚下载的hadoop只是存在/usr/local/Cellar目录下的，在全局环境下不能用hadoop命令。只有将其link到bin里（hadoop产生了27个symbolink），才能全局使用hadoop命令。在用brew install时会默认完成link的操作，除非出现意外。</p><p>意外：在安装hadoop时出现了</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Error: The `brew link` step did not complete successfully</span><br><span class="line">The formula built, but is not symlinked into /usr/local</span><br><span class="line">Could not symlink sbin/FederationStateStore</span><br><span class="line">/usr/local/sbin is not writable.</span><br></pre></td></tr></table></figure><p>是因为我本机根本没有这个目录，同时权限也不够，所以我建了这个目录，然后用</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo chown -r $(whoami) $(brew --prefix)/*</span><br></pre></td></tr></table></figure><p>修改了对应权限，成功安装。这里引出了</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew --prefix</span><br></pre></td></tr></table></figure><p>这个是指brew存在的目录，其他brew操作都是在这个目录下搞的（例如cellar就是在这个目录下）。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;现在新的mac基本都内置homebrew了吧，brew可以说是mac神器之一了。上手简单，但还是用法需要整理一下：&lt;/p&gt;
&lt;p&gt;###brew常用命令&lt;/p&gt;
&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gu
      
    
    </summary>
    
    
      <category term="mac" scheme="http://yoursite.com/tags/mac/"/>
    
  </entry>
  
  <entry>
    <title>hip-hop中一些slang积累</title>
    <link href="http://yoursite.com/2018/07/27/hip-hop%E4%B8%AD%E4%B8%80%E4%BA%9Bslang%E7%A7%AF%E7%B4%AF/"/>
    <id>http://yoursite.com/2018/07/27/hip-hop中一些slang积累/</id>
    <published>2018-07-27T15:25:18.747Z</published>
    <updated>2018-08-10T10:36:41.627Z</updated>
    
    <content type="html"><![CDATA[<p>听了很久trap，很多都不太懂，之后不懂的就写在这里吧～</p><p>###In my feelings - Drake （KIKI在b榜第一呆了一个月，我满耳朵都是kiki）</p><p>Henny -&gt; Hennessy：轩尼诗（酒）</p><p>wraith：幽灵、幻影（劳斯莱斯品牌）</p><p>code to the safe：保险箱密码</p><p>Neck work：类似的表达有give me some neck，指吹喇叭，等同于blow job或者sucking或者blowing of one’s dick~</p><p>Netflix and chill：一个internet meme，指约pao</p><p>net worth；资产净值（身价）</p><h3 id="Alright-Kendrick-Lamar"><a href="#Alright-Kendrick-Lamar" class="headerlink" title="Alright - Kendrick Lamar"></a>Alright - Kendrick Lamar</h3><p>Mac-11：机械手枪的型号</p><p>Pussy&amp;Benjamin：指代女人和金钱</p><p>Chevy -&gt; chevrolet 雪弗兰</p><p>Get reaping everything I sow：收获我所播种的（种豆得豆）</p><p>My karma：我的命运</p><p>Preliminary hearing：法庭的初审</p><p>fight my vice：和恶习斗争（vice除了副的还有恶习的意思）</p><p>Popo：police，条子</p><p>Preacher：牧师，传道人</p><p>Regal：君主的，这里指别克君威车</p><p>Resentment：愤恨，不满</p><p>Self destruct：自我毁灭</p><p>Lucy -&gt; Lucifer：是指撒旦，Satan, the devil（貌似只有lamar称lucifer为lucy～）</p><h3 id="Bed-Nicki-Minaj-Ariana-Grande-（沉迷黄歌，无法自拔～）"><a href="#Bed-Nicki-Minaj-Ariana-Grande-（沉迷黄歌，无法自拔～）" class="headerlink" title="Bed - Nicki Minaj/Ariana Grande （沉迷黄歌，无法自拔～）"></a>Bed - Nicki Minaj/Ariana Grande （沉迷黄歌，无法自拔～）</h3><p>wit’(with) your name on it：属于某人（不是真的指文字那种）</p><p>Sheet：床单</p><p>Carter III：指Lil Wayne备受赞誉的专辑</p><p>A Milli：Carter III专辑中的一首歌</p><p>GOAT：greatest of all time 史上最佳</p><p>turn down：拒绝（don’t turn me down不要拒绝我）</p><p>Lingerie：内衣如图，不解释</p><p><img src="/Users/max/Documents/Blog/source/img/lingerie.png" alt="img"></p><p>blow it like a feather on you：像一片羽毛xx你（撩的不行啊～）</p><p>Starting five：指nba那种首发五人，也可以用 Starting Line-up（首发阵容）</p><p>Thick skin：脸皮厚，不怕被骂～</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;听了很久trap，很多都不太懂，之后不懂的就写在这里吧～&lt;/p&gt;
&lt;p&gt;###In my feelings - Drake （KIKI在b榜第一呆了一个月，我满耳朵都是kiki）&lt;/p&gt;
&lt;p&gt;Henny -&amp;gt; Hennessy：轩尼诗（酒）&lt;/p&gt;
&lt;p&gt;wrait
      
    
    </summary>
    
    
      <category term="hiphop" scheme="http://yoursite.com/tags/hiphop/"/>
    
  </entry>
  
  <entry>
    <title>pandas的一些东西整理</title>
    <link href="http://yoursite.com/2018/07/24/pandas%E7%9A%84%E4%B8%80%E4%BA%9B%E4%B8%9C%E8%A5%BF/"/>
    <id>http://yoursite.com/2018/07/24/pandas的一些东西/</id>
    <published>2018-07-24T14:55:02.595Z</published>
    <updated>2018-08-10T16:37:23.714Z</updated>
    
    <content type="html"><![CDATA[<p>之前看了numpy，这两天看了pandas，也在这里整理一下。</p><h3 id="新建"><a href="#新建" class="headerlink" title="新建"></a>新建</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">'key1'</span>:[<span class="string">'value11,value12'</span>],</span><br><span class="line">    <span class="string">'key2'</span>:[<span class="string">'value21'</span>,<span class="string">'value22'</span>]   </span><br><span class="line">       &#125;</span><br><span class="line">df = pd.DataFrame(data)</span><br><span class="line"></span><br><span class="line">df.index<span class="comment">#描述dataframe的index的【开始/结束）和步长，注意这个是指df的index而非数据的id</span></span><br><span class="line">df.columns<span class="comment">#行名</span></span><br><span class="line">df.dtypes<span class="comment">#类型</span></span><br><span class="line">df.size<span class="comment">#数据总数</span></span><br><span class="line">df.shape<span class="comment">#数据形式（行，列）</span></span><br><span class="line">df.ndim<span class="comment">#维度</span></span><br><span class="line">df.T<span class="comment">#转置</span></span><br></pre></td></tr></table></figure><h3 id="从数据库中得到数据-amp-amp-将数据写入数据库"><a href="#从数据库中得到数据-amp-amp-将数据写入数据库" class="headerlink" title="从数据库中得到数据 &amp;&amp; 将数据写入数据库"></a>从数据库中得到数据 &amp;&amp; 将数据写入数据库</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sqlalchemy <span class="keyword">import</span> create_engine</span><br><span class="line"></span><br><span class="line"><span class="comment">#连接mysql数据库</span></span><br><span class="line">engine = create_engine(<span class="string">'mysql+pymysql://root:qh129512@127.0.0.1:3306/testdb?charset=utf8'</span>)</span><br><span class="line"></span><br><span class="line">sql = <span class="string">'select * from person'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#下面有三种获取数据的方式，返回的formlist就是一个dataframe</span></span><br><span class="line">formlist = pd.read_sql_query(sql,con=engine)<span class="comment">#参数为sql语句</span></span><br><span class="line">formlist = pd.read_sql_table(table,con=engine)<span class="comment">#参数为表名</span></span><br><span class="line">formlist = pd.read_sql(sql,con=engine)<span class="comment">#参数可以是sql语句，也可以表名</span></span><br></pre></td></tr></table></figure><p>下面是将数据写入数据库</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df = pd.DataFrame(data,columns=[<span class="string">'name,birthday'</span>])<span class="comment">#这里的columns就是指dataframe里有哪些comlumn，这里没有的df里也不会有，如果不添加columns这个参数就默认data中全部数据</span></span><br><span class="line"></span><br><span class="line">df.to_sql(name=<span class="string">'person'</span>,con=engine, if_exists=<span class="string">'append'</span>,index=<span class="keyword">False</span>)</span><br><span class="line"><span class="comment">#if_exists:有三种fail-&gt;表存在就不写入；replace-&gt;表存在就删掉原来的表重新创建；append-&gt;在原表基础上追加数据。默认为fail</span></span><br><span class="line"><span class="comment">#index：决定是否将行索引作为数据传入数据库，注意：如果数据库没有专门来存这个的就false，因为表里没有这里用true会有问题</span></span><br></pre></td></tr></table></figure><h3 id="使用dataframe"><a href="#使用dataframe" class="headerlink" title="使用dataframe"></a>使用dataframe</h3><p>直接取某个、某些数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'name'</span>][<span class="number">0</span>]</span><br><span class="line">df.name[:<span class="number">5</span>]</span><br><span class="line">df[[<span class="string">'name'</span>,<span class="string">'birthday'</span>]][:<span class="number">2</span>]</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure><p>取数据的切片</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">df.loc[:<span class="number">5</span>,<span class="string">'name'</span>]<span class="comment">#前一个参数为行索引，后一个是列索引名称</span></span><br><span class="line">df.iloc[<span class="number">0</span>:<span class="number">2</span>,<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#有条件的切片</span></span><br><span class="line">df.loc[(df[<span class="string">'name'</span>] == <span class="string">'max'</span>),:]<span class="comment">#取name为max的切片</span></span><br><span class="line"></span><br><span class="line">df.iloc[(df[<span class="string">'name'</span>] == <span class="string">'max'</span>).values,:]</span><br></pre></td></tr></table></figure><p>这里有两个函数，loc和iloc，区别有</p><ul><li>loc第一个参数可以为series，例如我传入一个条件，其实相当于一个Series([True,True,False…])这种形式；iloc不可以穿series，但能传一个array，所以可以通过.values的形式传入条件</li><li>行索引时loc是前后闭区间，而iloc是前闭后开区间（python中这种更常见）</li></ul><p>删除数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df.drop(labels=rang(<span class="number">9</span>,<span class="number">10</span>),axis=<span class="number">0</span>,inplace=<span class="keyword">True</span>)</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">labels接收string、array，表示删除行/列的标签</span></span><br><span class="line"><span class="string">axis接收0、1，表示操作轴向，0为横，1为纵</span></span><br><span class="line"><span class="string">inplace接收boolean，代表操作是否对原数据生效</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure><p>对dataframe中数据修改</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#直接声明就可以添加一列，如</span></span><br><span class="line">df[<span class="string">'prefix_name'</span>] = <span class="string">'MAC_'</span> + df[<span class="string">'name'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#修改某个数据可以将其找出来然后直接赋值</span></span><br><span class="line">df.loc[(df.name == <span class="string">'max'</span>),<span class="string">'name'</span>] = <span class="string">'maxhh'</span></span><br></pre></td></tr></table></figure><p>随机数的使用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">series = pd.Series(np.random.randint(high=<span class="number">10000</span>,low=<span class="number">1000</span>,size=<span class="number">8</span>))<span class="comment">#产生一个随机series</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">df.loc[:,<span class="string">'net-worth'</span>] = series<span class="comment">#将series值付给df</span></span><br></pre></td></tr></table></figure><p>dataframe算数统计</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'net-worth'</span>].mean()<span class="comment">#平均值</span></span><br><span class="line">np.mean(df[<span class="string">'net-worth'</span>])<span class="comment">#另一种计算平均值的方法</span></span><br><span class="line">df[<span class="string">'net-worth'</span>].min()<span class="comment">#最小值</span></span><br><span class="line">df[<span class="string">'net-worth'</span>].describe()<span class="comment">#描述，包含很多数据可以用！</span></span><br><span class="line">nullNum = df.shape[<span class="number">0</span>] - df[<span class="string">'name'</span>].count()<span class="comment">#统计有多少空值</span></span><br></pre></td></tr></table></figure><h3 id="Category类型的使用"><a href="#Category类型的使用" class="headerlink" title="Category类型的使用"></a>Category类型的使用</h3><p>可以将某一列转化成category类型，这样相当于做了一次分类处理，这样得到的描述性信息会很多</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'name'</span>] = df[<span class="string">'name'</span>].astype(<span class="string">'category'</span>)<span class="comment">#注意这里是赋值而不是调用</span></span><br><span class="line"></span><br><span class="line">df[<span class="string">'name'</span>].describe()</span><br></pre></td></tr></table></figure><h3 id="时间类型"><a href="#时间类型" class="headerlink" title="时间类型"></a>时间类型</h3><p>pandas里有很多时间类型，不同类型用处不同。如timestamp主要用来记录时间，而timedelta用来做时间运算</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#有很多方法创建或转化出一个timestamp</span></span><br><span class="line">today_date = pd.to_datetime(<span class="string">'2018-8/5'</span>)<span class="comment">#随意的一个string都可以识别</span></span><br></pre></td></tr></table></figure><p>注意一个概念，从数据库一个datatime拿出来的时间如果调用dtype的话发现是(‘&lt;M8[ns]’)类似的类型，展开来说：</p><p>这个是属于机器的比较特别的类型:<br>小端机器的类型：datatime[ns] == &lt;M8[ns]<br>大端机器的类型：datatime[ns] == &gt;M8[ns]<br>这个可以通过</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">np.dtype(<span class="string">'datetime64[ns]'</span>) == np.dtype(<span class="string">'&lt;M8[ns]'</span>)</span><br><span class="line"><span class="comment">#out: True</span></span><br></pre></td></tr></table></figure><p>证明。<br>所以当数据库中取出就是这种类型时，不需要再进行处理，但如果取出是个object，则用pd.to_datatime处理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'birthday'</span>] = pd.to_datatime(df[<span class="string">'birthday'</span>])</span><br></pre></td></tr></table></figure><p>这里要熟悉的操作有：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">user_birthday = [i.year <span class="keyword">for</span> i <span class="keyword">in</span> df[<span class="string">'birthday'</span>]]<span class="comment">#返回所有年份的list</span></span><br><span class="line"></span><br><span class="line">birthday = df[df[<span class="string">'birthday'</span>]&lt;=pd.datetime(<span class="number">1991</span>,<span class="number">1</span>,<span class="number">1</span>)]<span class="comment">#按条件取时间时，一定要那拿timestamp与对应的pdf.datetime()相比</span></span><br></pre></td></tr></table></figure><p>还有时间做加减法也是支持的,timestamp可以加一个tmiedelta来做时间的计算。注意timedelta的参数为weeks,days,hours以及更小的时间<br>直接用+，-符号就可以做计算了。相反的，想算两个时间差，只要用两个datetime做减法，即可得到timedelta类型的时间差距</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">aweek_after = date + pd.Timedelta(weeks = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">today_date = pd.to_datetime(<span class="string">'2018-8-5'</span>)</span><br><span class="line"></span><br><span class="line">time_delta = aweek_after - today_date<span class="comment">#两个timestamp做减法，得到了一个timedelta类型的时间差</span></span><br></pre></td></tr></table></figure><h3 id="分组和聚合"><a href="#分组和聚合" class="headerlink" title="分组和聚合"></a>分组和聚合</h3><p>分组顾名思义，就是将数据按照一定条件进行分组，得到数据整体情况</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data_group = df.groupby(by=<span class="string">'birthday'</span>)</span><br><span class="line">data_group.count()</span><br></pre></td></tr></table></figure><p>这里的count()得到如下表结果</p><table><thead><tr><th></th><th>id</th><th>name</th><th>net-worth</th></tr></thead><tbody><tr><td>birthday</td><td></td><td></td><td></td></tr><tr><td>1987-01-10</td><td>1</td><td>1</td><td>1</td></tr><tr><td>1989-03-10</td><td>6</td><td>0</td><td>4</td></tr><tr><td>1993-08-05</td><td>1</td><td>1</td><td>1</td></tr><tr><td>1995-12-12</td><td>1</td><td>1</td><td>1</td></tr><tr><td>1996-10-12</td><td>1</td><td>1</td><td>1</td></tr></tbody></table><p>分组的直接结果并不能直接看，因为它返回的只是一个地址，但可以方便的查分组后的一些属性，如：count，head，max等等</p><p>聚合，就是将一组数据做aggretate，聚合的函数自己定</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'net-worth'</span>].agg([np.sum,np.mean])<span class="comment">#针对net-worth数据计算两种agg，分别以sum和mean</span></span><br><span class="line"></span><br><span class="line">df.agg(&#123;<span class="string">'net-worth'</span>:[np.sum,sp.mean]&#125;)<span class="comment">#针对不同数据要进行不同的agg，可以用key-value的方式</span></span><br></pre></td></tr></table></figure><p>agg函数的参数是计算函数，这个函数可以用numpy中一些简单的统计函数，如果复杂也可以自定义，如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Trinum</span><span class="params">(data)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> data.sum()*<span class="number">2</span></span><br><span class="line">    </span><br><span class="line">df[<span class="string">'net-worth'</span>].agg(Trinum)<span class="comment">#agg函数的参数可以是函数，该函数将data传入做处理，然后返回即可</span></span><br><span class="line"><span class="comment">#稍微注意下sum后面的括号，没有括号是函数，有括号的是执行，但必须声明参数</span></span><br><span class="line"></span><br><span class="line">df[<span class="string">'net-worth'</span>].agg(<span class="keyword">lambda</span> x:x*<span class="number">2</span>)<span class="comment">#agg的参数可以是lambda函数</span></span><br></pre></td></tr></table></figure><p>这里的一个例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.groupby(by=<span class="string">'birthday'</span>).agg(np.mean)<span class="comment">#完全等价于data_group.mean()，都是求每组的平均值</span></span><br></pre></td></tr></table></figure><p>当然，apply函数、transform函数和agg函数也大部分相同，但apply方法不能用key-value类型来特定的处理，transform方法只有一个参数function</p><h3 id="创建透视表"><a href="#创建透视表" class="headerlink" title="创建透视表"></a>创建透视表</h3><p>可以通过pandas创建透视表</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.pivot_table(df[[<span class="string">'id'</span>,<span class="string">'name'</span>,<span class="string">'net-worth'</span>]],index=[<span class="string">'id'</span>],columns=<span class="string">'name'</span>,fill_value=<span class="number">0</span>)<span class="comment">#不显示无index的值</span></span><br></pre></td></tr></table></figure><p>得到</p><table><thead><tr><th></th><th>net-worth</th><th></th><th></th><th></th></tr></thead><tbody><tr><td>name</td><td>hape</td><td>john</td><td>johnny</td><td>max</td></tr><tr><td>id</td><td></td><td></td><td></td><td></td></tr><tr><td>1</td><td>0</td><td>0</td><td>0</td><td>6355</td></tr><tr><td>2</td><td>0</td><td>6567</td><td>0</td><td>0</td></tr><tr><td>4</td><td>0</td><td>0</td><td>8491</td><td>0</td></tr><tr><td>8</td><td>6872</td><td>0</td><td>0</td><td>0</td></tr></tbody></table><p>但这不是pandas的重点，略～</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;之前看了numpy，这两天看了pandas，也在这里整理一下。&lt;/p&gt;
&lt;h3 id=&quot;新建&quot;&gt;&lt;a href=&quot;#新建&quot; class=&quot;headerlink&quot; title=&quot;新建&quot;&gt;&lt;/a&gt;新建&lt;/h3&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;
      
    
    </summary>
    
    
      <category term="data science" scheme="http://yoursite.com/tags/data-science/"/>
    
  </entry>
  
  <entry>
    <title>看了一点zookeeper的心得</title>
    <link href="http://yoursite.com/2018/07/20/%E7%9C%8B%E4%BA%86%E4%B8%80%E7%82%B9zookeeper%E7%9A%84%E5%BF%83%E5%BE%97/"/>
    <id>http://yoursite.com/2018/07/20/看了一点zookeeper的心得/</id>
    <published>2018-07-19T16:10:42.509Z</published>
    <updated>2018-08-10T10:39:23.185Z</updated>
    
    <content type="html"><![CDATA[<p>###Fast Paxos算法：</p><p>这个还没看，先留个坑把。</p><p>###文件结构：</p><p>zookeeper的文件结构大概是这个样子的：</p><p>!å¾ 1 Zookeeper æ°æ®ç”æ](<a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-zookeeper/image001.gif" target="_blank" rel="noopener">https://www.ibm.com/developerworks/cn/opensource/os-cn-zookeeper/image001.gif</a>)</p><h3 id="znode（data-node）："><a href="#znode（data-node）：" class="headerlink" title="znode（data node）："></a>znode（data node）：</h3><ol><li>其中的每个子目录就是一个znode，他们也可以有子的znode（临时znode除外）。</li><li>这些znode必须是绝对路径，不允许相对路径。</li><li>每个znode都维护一个stat structure（linux系统文件的结构），其中包括版本号，acl改变等等。每次更新数据会让版本号自增。</li><li>每个znode可以设置一个watches，当watch触发后，zookeeper将发给client一个提醒。</li><li>在znode中数据读写是原子性的。每个znode都有一个ACL（access control list）来控制其读写权限。zookeeper不是用来做数据库的，其中存储的数据可能都是几kb的配置/状态信息。大块数据都存在hdfs中。</li><li>Ephemeral node就是临时节点，每次会话结束这些节点都会清空，不允许有子节点。</li></ol><p>###Zookeeper Session：</p><p><img src="/Users/max/Documents/Blog/source/img/state_dia.jpg" alt="state_dia"></p><p>###一致性的保证：</p><p>zookeeper是一个非常高效、可扩展的服务。其一致性靠以下几点保证：</p><ol><li>顺序的一致性。一个client的更新会依序发送给其他。</li><li>原子性。更新是原子操作，只有成功和失败，没有中间过程。</li><li>服务器会看到完全相同的服务，不论其连接了哪个服务器。</li><li>可靠性。一旦一个更新被部署，他会一直存在，直到被另一个更新覆盖。</li><li>及时性。client对系统的观察在一个时间段内将是最新的。也即系统的改变在这个时间段内client是看见的，或者可以探测到它失败。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;###Fast Paxos算法：&lt;/p&gt;
&lt;p&gt;这个还没看，先留个坑把。&lt;/p&gt;
&lt;p&gt;###文件结构：&lt;/p&gt;
&lt;p&gt;zookeeper的文件结构大概是这个样子的：&lt;/p&gt;
&lt;p&gt;!å¾ 1 Zookeeper æ°æ®ç”æ](&lt;a href=&quot;https:
      
    
    </summary>
    
    
      <category term="big data" scheme="http://yoursite.com/tags/big-data/"/>
    
  </entry>
  
  <entry>
    <title>从numpy入手</title>
    <link href="http://yoursite.com/2018/07/18/%E4%BB%8Enumpy%E5%85%A5%E6%89%8B/"/>
    <id>http://yoursite.com/2018/07/18/从numpy入手/</id>
    <published>2018-07-18T02:26:21.042Z</published>
    <updated>2018-08-10T16:39:20.271Z</updated>
    
    <content type="html"><![CDATA[<p>最近看了一些numpy的基础，在这里整理一下。</p><h3 id="创建："><a href="#创建：" class="headerlink" title="创建："></a>创建：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#数组</span></span><br><span class="line">array1 = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]])</span><br><span class="line">np.eye(<span class="number">3</span>)<span class="comment">#单位多维数组</span></span><br><span class="line">np.diag([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])<span class="comment">#对角多维数组</span></span><br><span class="line">np.arange(<span class="number">1</span>,<span class="number">4</span>)<span class="comment">#[1,2,3]数组</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#矩阵</span></span><br><span class="line">np.mat(<span class="string">"1 2 3;4 5 6;7 8 9"</span>)<span class="comment">#矩阵运算与多维数组运算结果不同，所以要用mat建矩阵，用分号隔开数据</span></span><br><span class="line">matrix = np.mat(array1)<span class="comment">#可以用多维数组初始化矩阵</span></span><br><span class="line">matrix1 = np.bmat(<span class="string">"array1 array2;array1 array2"</span>)<span class="comment">#创建分块矩阵</span></span><br></pre></td></tr></table></figure><h3 id="随机数："><a href="#随机数：" class="headerlink" title="随机数："></a>随机数：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">np.random.random(<span class="number">100</span>)<span class="comment">#完全随机</span></span><br><span class="line">np.random.rand(<span class="number">5</span>,<span class="number">5</span>)<span class="comment">#5*5均匀分布</span></span><br><span class="line">np.random.randn(<span class="number">5</span>,<span class="number">5</span>)<span class="comment">#5*5正态分布</span></span><br><span class="line">np.random.randint(<span class="number">2</span>,<span class="number">50</span>,size=(<span class="number">2</span>,<span class="number">3</span>),dtype=<span class="string">'l'</span>)<span class="comment">#大于等于2小于50的2*3的int64型整数</span></span><br></pre></td></tr></table></figure><h3 id="变换数组形态："><a href="#变换数组形态：" class="headerlink" title="变换数组形态："></a>变换数组形态：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">arr.reshape(<span class="number">3</span>,<span class="number">3</span>)<span class="comment">#转变成3*3的数组，但要求原数组必须9个元素，否则不能reshape</span></span><br><span class="line">np.hstack((arr1,arr2))<span class="comment">#横向组合</span></span><br><span class="line">np.vsplit(arr4,<span class="number">3</span>)<span class="comment">#横向切割，即把横向由1列的变成3列（相当于横着切）</span></span><br></pre></td></tr></table></figure><h3 id="文件存储与读取"><a href="#文件存储与读取" class="headerlink" title="文件存储与读取"></a>文件存储与读取</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#二进制存储与读取</span></span><br><span class="line"><span class="comment">#存储</span></span><br><span class="line">file = <span class="string">"./temp/save_arr.npy"</span></span><br><span class="line">filez = <span class="string">"./temp/save_arr.npz"</span></span><br><span class="line">np.save(file,arr)<span class="comment">#用save存，文件扩展名.npy，只能存一个数组</span></span><br><span class="line">np.savez(filez,arr1[,arr2...])<span class="comment">#用savez存，文件扩展名.npz，可以存多个数组。注意：不按照要求扩展名，则系统自己添加对应扩展名；二进制存储的数组打开文件看不到真实数据</span></span><br><span class="line"><span class="comment">#读取</span></span><br><span class="line">loaded_data = np.load(file)<span class="comment">#存储可以省略扩展名，读取一定不可以</span></span><br><span class="line">loaded_dataz = np.load(filez)</span><br><span class="line">loaded_dataz[<span class="string">"arr_0"</span>]<span class="comment">#对于多个文件读取，这种方式可以得到单独数组</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#文件存储与读取</span></span><br><span class="line"><span class="comment">#存储</span></span><br><span class="line">np.savetxt(fname,x,fmt=<span class="string">'%d'</span>,delimiter=<span class="string">','</span>,newline=<span class="string">'\n'</span>,header=<span class="string">''</span>,footer=<span class="string">''</span>,comments=<span class="string">'# '</span>)<span class="comment">#x为要存的数组，fmt='%d'表示整数方式存，delimiter表示存储时的分隔符，存储和读取时默认为空格</span></span><br><span class="line"><span class="comment">#读取</span></span><br><span class="line">loaded_data = np.loadtxt(fname,delimiter=<span class="string">","</span>)<span class="comment">#一定也要带上啊delimiter且与文件中的分隔符一致</span></span><br></pre></td></tr></table></figure><h3 id="利用numpy做简单的统计分析"><a href="#利用numpy做简单的统计分析" class="headerlink" title="利用numpy做简单的统计分析"></a>利用numpy做简单的统计分析</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">10</span>)<span class="comment">#种子是伪随机数的开头，相同种子对应随机数都相同，一般种子会设为当前时间，确保得到真随机数（numpy默认也是这样）</span></span><br><span class="line">arr = np.random.randint(<span class="number">1</span>,<span class="number">10</span>,size=<span class="number">10</span>)</span><br><span class="line"><span class="comment">#排序</span></span><br><span class="line">arr.sort()<span class="comment">#这个会直接将arr排序</span></span><br><span class="line">arr.sort(axis=<span class="number">0</span>)<span class="comment">#二维数组的sort参数axis可以为0、1，分别对应数组纵向和横向的排序</span></span><br><span class="line"><span class="comment">#去重</span></span><br><span class="line">np.unique(arr)</span><br><span class="line"><span class="comment">#重复</span></span><br><span class="line">np.tile(arr,<span class="number">3</span>)<span class="comment">#arr是重复哪个，3是重复次数</span></span><br><span class="line">np.repeat(arr,<span class="number">3</span>,axis=<span class="number">0</span>)<span class="comment">#axis是重复的方向（tile没有这个参数）</span></span><br><span class="line"><span class="comment">#注意：tile是对数组进行重复，repeat则是对每一个数组的每一个元素进行重复，打破了原来的数组。</span></span><br><span class="line"><span class="comment">#常用统计函数</span></span><br><span class="line">np.sum(arr)<span class="comment">#求和</span></span><br><span class="line">arr.sum(axis=<span class="number">0</span>)<span class="comment">#沿纵轴求和</span></span><br><span class="line">np.mean(arr)<span class="comment">#计算数组均值</span></span><br><span class="line">arr.mean(axis = <span class="number">0</span>)<span class="comment">#沿着纵轴计算数组均值</span></span><br><span class="line">np.std(arr)<span class="comment">#计算标准差</span></span><br><span class="line">np.var(arr)<span class="comment">#计算方差</span></span><br><span class="line">np.min(arr)<span class="comment">#计算最小值</span></span><br><span class="line">np.max(arr)<span class="comment">#计算最大值</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近看了一些numpy的基础，在这里整理一下。&lt;/p&gt;
&lt;h3 id=&quot;创建：&quot;&gt;&lt;a href=&quot;#创建：&quot; class=&quot;headerlink&quot; title=&quot;创建：&quot;&gt;&lt;/a&gt;创建：&lt;/h3&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;tabl
      
    
    </summary>
    
    
      <category term="data science" scheme="http://yoursite.com/tags/data-science/"/>
    
  </entry>
  
  <entry>
    <title>最近在看的东西</title>
    <link href="http://yoursite.com/2018/07/16/20180716%E6%97%A5%E8%AE%B0/"/>
    <id>http://yoursite.com/2018/07/16/20180716日记/</id>
    <published>2018-07-16T09:12:39.376Z</published>
    <updated>2018-08-10T10:38:03.271Z</updated>
    
    <content type="html"><![CDATA[<p>最近都没有写博客，想更一篇了。</p><p>前几天在刷算法，这几天看了一些springboot的东西。之前对spring了解的也比较多，而且这次看的也比较浅，就这样吧。</p><p>感觉很慌。马上要找工作了，我却还没开始工作…</p><p>spring-boot用的时候再看吧，</p><p>算法还是要接着刷，</p><p>接下来就做我的python了！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近都没有写博客，想更一篇了。&lt;/p&gt;
&lt;p&gt;前几天在刷算法，这几天看了一些springboot的东西。之前对spring了解的也比较多，而且这次看的也比较浅，就这样吧。&lt;/p&gt;
&lt;p&gt;感觉很慌。马上要找工作了，我却还没开始工作…&lt;/p&gt;
&lt;p&gt;spring-boot用的时
      
    
    </summary>
    
    
      <category term="life" scheme="http://yoursite.com/tags/life/"/>
    
  </entry>
  
  <entry>
    <title>anaconda基础</title>
    <link href="http://yoursite.com/2018/07/04/%E6%96%B0%E7%9A%84%E5%B0%9D%E8%AF%95/"/>
    <id>http://yoursite.com/2018/07/04/新的尝试/</id>
    <published>2018-07-04T12:20:26.782Z</published>
    <updated>2018-08-10T10:36:31.409Z</updated>
    
    <content type="html"><![CDATA[<p>这是一个python环境、包管理工具，这玩意很厉害。</p><h3 id="插一个其他东西："><a href="#插一个其他东西：" class="headerlink" title="插一个其他东西："></a>插一个其他东西：</h3><p>在搞conda环境变量的时候在.zshrc里没有注意语句的顺序，变量使用在前，声明在后，导致path里没有这个。。。。。。以后要注意了！</p><p>###使用原因：</p><ol><li>和以前用的virtualenv有点像，可以创建一个独立的python环境，python版本，包都是独立于外部的。</li><li>自带很多数据科学的包，省的下。</li><li>可以将环境与远程同步，也可以clone别人的环境，开发效率高。</li><li>可以与pycharm等工具结合，通用性强。</li><li>Anaconda navigator是一个桌面应用，使用非常简单。</li></ol><p>###常用到的操作：</p><ol><li>在命令行可以用conda来操作一些东西：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">conda create -n &lt;env-name&gt; &lt;package-name&gt;<span class="comment">#创建conda环境</span></span><br><span class="line"></span><br><span class="line">conda remove -n &lt;env-name&gt;<span class="comment">#删除conda环境</span></span><br><span class="line"></span><br><span class="line">conda env list<span class="comment">#查看所有环境，其中带*的为当前环境，在当前环境下，用的python版本、包等都是anaconda的，而不是本机环境</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> activate &lt;env-name&gt;<span class="comment">#激活某个环境，之后zsh前面会加上这个环境的名称</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> deactivate<span class="comment">#退出某个环境</span></span><br><span class="line"></span><br><span class="line">conda install &lt;package-name&gt;[=versionInfo]<span class="comment">#在当前环境下安装包，可以选定版本</span></span><br><span class="line"></span><br><span class="line">conda install -n &lt;env-name&gt; &lt;package-name&gt;<span class="comment">#在特定环境中</span></span><br><span class="line"></span><br><span class="line">conda list<span class="comment">#列出当前环境所有的包</span></span><br><span class="line"></span><br><span class="line">conda search &lt;package-name&gt;<span class="comment">#查找某个包（模糊匹配）</span></span><br></pre></td></tr></table></figure><p>###conda和pycharm的结合：</p><p>pycharm可以直接用conda的environment来做，只要在选择interpreter的时候选conda环境对应的那个即可。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这是一个python环境、包管理工具，这玩意很厉害。&lt;/p&gt;
&lt;h3 id=&quot;插一个其他东西：&quot;&gt;&lt;a href=&quot;#插一个其他东西：&quot; class=&quot;headerlink&quot; title=&quot;插一个其他东西：&quot;&gt;&lt;/a&gt;插一个其他东西：&lt;/h3&gt;&lt;p&gt;在搞conda环境变量的
      
    
    </summary>
    
    
      <category term="data science" scheme="http://yoursite.com/tags/data-science/"/>
    
  </entry>
  
  <entry>
    <title>一些简单的命令行操作总结</title>
    <link href="http://yoursite.com/2018/07/04/%E4%B8%80%E4%BA%9B%E7%AE%80%E5%8D%95%E7%9A%84%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%93%8D%E4%BD%9C%E6%80%BB%E7%BB%93/"/>
    <id>http://yoursite.com/2018/07/04/一些简单的命令行操作总结/</id>
    <published>2018-07-04T10:03:57.407Z</published>
    <updated>2018-08-10T10:37:17.965Z</updated>
    
    <content type="html"><![CDATA[<p>今天看了一些oh-my-zsh的东西，感觉还是要整理在博客中，不然太容易忘掉了。</p><p>###插件：</p><p>zsh自带很多插件，可以在.zshrc的plugin里写入，就可以用这些插件了，我用的插件包括：</p><ul><li>z。可以直接跳转。它记录（统计）了一些常用的跳转，只要z+destination就可以</li><li>extract。可以直接解压，忽略tar后各种参数。与unzip类似。</li><li>zsh-autosuggestions。这个神器，之前输入的命令可以再提示出来，很方便用。</li><li>Web-search。可以在命令行直接用 google+要查的内容 即可打开搜索页面。</li></ul><h3 id="命令行快捷键："><a href="#命令行快捷键：" class="headerlink" title="命令行快捷键："></a>命令行快捷键：</h3><ul><li>ctrl+q。可以直接删除整行命令。</li><li>ctrl+w。可以删除每一分段的命令。</li><li>ctrl+e。直接跳到命令最后。</li><li>ctrl+a。直接跳到命令最前面。</li><li>command+d 在iterm中分屏</li><li>comand+[ or ] 在iterm的分屏中切换</li></ul><h3 id="ssh的key的名字问题："><a href="#ssh的key的名字问题：" class="headerlink" title="ssh的key的名字问题："></a>ssh的key的名字问题：</h3><p>忘记有什么问题了。。。整理不及时呐～</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;今天看了一些oh-my-zsh的东西，感觉还是要整理在博客中，不然太容易忘掉了。&lt;/p&gt;
&lt;p&gt;###插件：&lt;/p&gt;
&lt;p&gt;zsh自带很多插件，可以在.zshrc的plugin里写入，就可以用这些插件了，我用的插件包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;z。可以直接跳转。它记录（
      
    
    </summary>
    
    
      <category term="mac" scheme="http://yoursite.com/tags/mac/"/>
    
  </entry>
  
  <entry>
    <title>Cryptocurrency Technologies</title>
    <link href="http://yoursite.com/2018/04/30/Cryptocurrency%20Technologies/"/>
    <id>http://yoursite.com/2018/04/30/Cryptocurrency Technologies/</id>
    <published>2018-04-30T08:27:54.000Z</published>
    <updated>2018-08-21T11:28:53.474Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Cryptocurrency-Technologies"><a href="#Cryptocurrency-Technologies" class="headerlink" title="Cryptocurrency Technologies"></a>Cryptocurrency Technologies</h1><p>Coursera course from Princeton University, here are some information and notes from the course.</p><h2 id="Cryptographic-Hash-Functions"><a href="#Cryptographic-Hash-Functions" class="headerlink" title="Cryptographic Hash Functions"></a>Cryptographic Hash Functions</h2><h3 id="basic-term"><a href="#basic-term" class="headerlink" title="basic term:"></a>basic term:</h3><ul><li>takes any string of any size as input</li><li>fixed-size output (We’ll use 256 bits )</li><li>efficiently computable</li></ul><h3 id="Security-properties"><a href="#Security-properties" class="headerlink" title="Security properties:"></a>Security properties:</h3><ul><li>collision-free</li><li>hiding</li><li>puzzle-friendly </li></ul><h3 id="collision-free"><a href="#collision-free" class="headerlink" title="collision-free"></a>collision-free</h3><h4 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h4><p>Nobody can find x and y such that:</p><blockquote><p> <strong>x!=y and H(x) = H(y)</strong>  </p></blockquote><p>So that is what we call collision-free.</p><p>Actually <strong>collision do exist. But it merely be found</strong> ——that is guaranteed the work.</p><h4 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h4><p>If we know H(x) = H(y), it’s safe to assume that x = y. Hash function provide us with a efficient way to recognize the same things. The hash is small, which has only 256 bits, while the whole things might be really big.</p><h3 id="Hiding"><a href="#Hiding" class="headerlink" title="Hiding"></a>Hiding</h3><h4 id="Definition-1"><a href="#Definition-1" class="headerlink" title="Definition"></a>Definition</h4><p>We want something like this:</p><blockquote><p>Given H(x), it is infeasible to find x.</p></blockquote><p>high min-entropy : the distribution is “very spread out”. If r is chosen from a probability distribution that has high min-entropy, then given H(r | x), it is infeasible to find x.</p><h4 id="Application-Commitment"><a href="#Application-Commitment" class="headerlink" title="Application : Commitment"></a>Application : Commitment</h4><p>Commit to a value, reveal it later.</p><blockquote><p><strong>com = H(key | msg)</strong></p></blockquote><h5 id="Hidding"><a href="#Hidding" class="headerlink" title="Hidding:"></a>Hidding:</h5><p>Given H(key | msg), infeasible to find msg.</p><h5 id="Binding"><a href="#Binding" class="headerlink" title="Binding:"></a>Binding:</h5><p>Infeasible to find msg != msg’ such that H(key | msg) == H(key | msg’)</p><h3 id="Puzzle-friendly"><a href="#Puzzle-friendly" class="headerlink" title="Puzzle-friendly"></a>Puzzle-friendly</h3><p>for every possible output value y, if k is chosen from a distribution with high min-entropy, then it is infeasible to find x such that H(k | x) = y.</p><h4 id="Application-Search-puzzle"><a href="#Application-Search-puzzle" class="headerlink" title="Application: Search puzzle"></a>Application: Search puzzle</h4><ol><li>given a “puzzle ID” id (from high min-entropy distrib), and a target set Y;</li><li>try to find a “solution” x such that H(id | x) = y.</li></ol><h2 id="Add"><a href="#Add" class="headerlink" title="Add:"></a>Add:</h2><p>common hash function in shell</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>md5</span><br><span class="line">md5 [-pqrtx] [-s string] [files ...]</span><br><span class="line"><span class="meta">#</span>more ways</span><br><span class="line">echo "max"|md5</span><br><span class="line">md5 &lt;&lt;&lt; "max"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>sha-1 &amp;&amp; sha-256</span><br><span class="line">shasum -a 1 -t test</span><br><span class="line">shasum -a 256 &lt;&lt;&lt; "max"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>encode and decode function -&gt; base64</span><br><span class="line">base64 -D &lt;&lt;&lt; "max" #decode</span><br><span class="line">base64 &lt;&lt;&lt; "max" #encode</span><br></pre></td></tr></table></figure><p>bitcoin use <strong>sha256</strong> as its hash function</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Cryptocurrency-Technologies&quot;&gt;&lt;a href=&quot;#Cryptocurrency-Technologies&quot; class=&quot;headerlink&quot; title=&quot;Cryptocurrency Technologies&quot;&gt;&lt;/a&gt;Crypt
      
    
    </summary>
    
    
      <category term="block chain" scheme="http://yoursite.com/tags/block-chain/"/>
    
  </entry>
  
</feed>
